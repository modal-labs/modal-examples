# ---
# output-directory: "/tmp/qwen-image-edit"
# ---

# # ä½¿ç”¨ Modal éƒ¨ç½²åƒé—®å›¾ç‰‡ç¼–è¾‘æ¨¡å‹ (Qwen-Image-Edit) - Diffusers æœ€ç»ˆç‰ˆ

# åœ¨è¿™ä¸ªä¾‹å­ä¸­ï¼Œæˆ‘ä»¬å°†åœ¨äº‘ç«¯GPUä¸Šè¿è¡Œé˜¿é‡Œçš„ Qwen-Image-Edit æ¨¡å‹ã€‚
# æˆ‘ä»¬å°†ä½¿ç”¨ Hugging Face å®˜æ–¹æ¨èçš„ diffusers åº“ä¸­çš„ QwenImageEditPipelineï¼Œ
# è¿™ç§æ–¹æ³•æ›´ç¨³å®šã€ä»£ç ä¹Ÿæ›´ç®€æ´ã€‚

# **æ–°å¢åŠŸèƒ½**: æˆ‘ä»¬è¿˜æ·»åŠ äº†ä¸€ä¸ª Web API ç«¯ç‚¹ï¼Œä»¥ä¾¿é€šè¿‡ HTTP POST è¯·æ±‚è°ƒç”¨æ­¤åŠŸèƒ½ã€‚

# æ¨¡å‹ä¸»é¡µ: https://huggingface.co/Qwen/Qwen-Image-Edit

from io import BytesIO
from pathlib import Path

import modal
from fastapi import File, Form, UploadFile
from fastapi.responses import Response


# 1. å®šä¹‰å®¹å™¨é•œåƒï¼šå®‰è£…æ‰€æœ‰å¿…è¦çš„åº“
image = (
    modal.Image.from_registry(
        "nvidia/cuda:12.1.1-devel-ubuntu22.04", # ä½¿ç”¨ä¸€ä¸ªå…¼å®¹çš„CUDAç‰ˆæœ¬
        add_python="3.11",
    )
    .apt_install("git")
    .pip_install(
        # ä½¿ç”¨ PyTorch Nightly ç‰ˆæœ¬ä»¥æ”¯æŒ diffusers çš„æœ€æ–°åŠŸèƒ½
        "torch",
        "torchvision",
        "transformers>=4.52.0",
        "diffusers>=0.27.0",
        "Pillow>=10.2.0",
        "huggingface-hub>=0.22.0",
        "accelerate>=0.29.0",
        "fastapi",             # **æ–°å¢**: æ·»åŠ  FastAPI ç”¨äºæ„å»º Web ç«¯ç‚¹
        "python-multipart",    # **æ–°å¢**: ç”¨äºå¤„ç†æ–‡ä»¶ä¸Šä¼ 
        # PyTorch çš„ Nightly index URL ä¸åŒï¼Œéœ€è¦æŒ‡å®š
        extra_index_url="https://download.pytorch.org/whl/nightly/cu121",
    )
)

# å®šä¹‰æ¨¡å‹åç§°å’Œç¼“å­˜è·¯å¾„
MODEL_NAME = "Qwen/Qwen-Image-Edit"
CACHE_DIR = Path("/cache")

# åˆ›å»ºä¸€ä¸ªæŒä¹…åŒ–çš„å­˜å‚¨å·æ¥ç¼“å­˜æ¨¡å‹ï¼Œé¿å…æ¯æ¬¡å¯åŠ¨éƒ½é‡æ–°ä¸‹è½½
cache_volume = modal.Volume.from_name("hf-hub-cache-qwen", create_if_missing=True)
volumes = {CACHE_DIR: cache_volume}

# ä»Modalå¹³å°å®‰å…¨åœ°è·å–HuggingFaceçš„APIå¯†é’¥
secrets = [modal.Secret.from_name("huggingface-secret")]

# é‡æ–°å‘½åAppä»¥ç¤ºåŒºåˆ†
app = modal.App("example-qwen-image-edit-diffusers")

@app.cls(
    image=image,
    gpu="A100-80GB",
    volumes=volumes,
    secrets=secrets,
    scaledown_window=240,
)
class Model:
    @modal.enter()
    def enter(self):
        """
        å®¹å™¨å¯åŠ¨æ—¶è¿è¡Œä¸€æ¬¡ï¼šä¸‹è½½å¹¶åŠ è½½æ¨¡å‹åˆ°GPUã€‚
        """
        import torch
        from diffusers import QwenImageEditPipeline

        print(f"æ­£åœ¨åŠ è½½æ¨¡å‹: {MODEL_NAME}")
        self.device = "cuda"

        # ä½¿ç”¨ Diffusers Pipeline ä»¥é«˜ç²¾åº¦åŠ è½½æ¨¡å‹
        self.pipe = QwenImageEditPipeline.from_pretrained(
            MODEL_NAME,
            torch_dtype=torch.bfloat16,
            cache_dir=CACHE_DIR,
        ).to(self.device)
        
        print("æ¨¡å‹åŠ è½½å®Œæˆï¼")

    @modal.method()
    def inference(self, image_bytes: bytes, prompt: str) -> bytes:
        """
        è¿™æ˜¯æ ¸å¿ƒçš„æ¨ç†å‡½æ•°ï¼Œä»æœ¬åœ°æ¥æ”¶å›¾ç‰‡å’ŒæŒ‡ä»¤ï¼Œåœ¨äº‘ç«¯GPUä¸Šæ‰§è¡Œï¼Œå¹¶è¿”å›æ–°å›¾ç‰‡ã€‚
        """
        import torch
        from PIL import Image

        print(f"æ”¶åˆ°æ–°çš„æ¨ç†ä»»åŠ¡ï¼ŒæŒ‡ä»¤: '{prompt}'")
        init_image = Image.open(BytesIO(image_bytes)).convert("RGB")
        
                # --- æ–°å¢ï¼šå®šä¹‰è´Ÿå‘æç¤ºè¯ ---
        negative_prompt = (
            "blurry text, distorted text, artifacts, watermark, signature, "
            "æ¨¡ç³Šçš„æ–‡å­—, å˜å½¢çš„æ–‡å­—, ä¹±ç , é”™è¯¯çš„ç¬”ç”», low quality, "
            "ä¹±åºæ–‡å­—, ä¸è‡ªç„¶çš„å­—ç¬¦, é”™è¯¯çš„å­—ä½“"
        )

        edited_image = self.pipe(
            image=init_image,
            prompt=prompt,
            negative_prompt=negative_prompt,
            num_inference_steps=50,
            guidance_scale=8.0,
            generator=torch.Generator(device=self.device).manual_seed(42),
        ).images[0]
        
        print("æ¨ç†å®Œæˆï¼Œæ­£åœ¨è¿”å›å›¾ç‰‡ã€‚")

        byte_stream = BytesIO()
        edited_image.save(byte_stream, format="PNG")
        output_image_bytes = byte_stream.getvalue()

        return output_image_bytes


# ä¿®å¤ï¼šæ·»åŠ  @app.function() è£…é¥°å™¨
@app.function(image=image)  # âœ… å…³é”®ä¿®å¤ï¼šå…³è”åˆ° app
@modal.fastapi_endpoint(method="POST")
async def edit_image(image: UploadFile = File(...), prompt: str = Form(...)):
    """
    ä¸€ä¸ªç”¨äºç¼–è¾‘å›¾ç‰‡çš„ Web API ç«¯ç‚¹ï¼Œä½¿ç”¨ multipart/form-data è¿›è¡Œ POST è¯·æ±‚ã€‚
    - 'image': éœ€è¦ç¼–è¾‘çš„å›¾ç‰‡æ–‡ä»¶ã€‚
    - 'prompt': ç”¨äºç¼–è¾‘çš„æ–‡æœ¬æŒ‡ä»¤ã€‚
    """
    print(f"æ”¶åˆ°æ¥è‡ª Web çš„è¯·æ±‚ï¼ŒæŒ‡ä»¤: '{prompt}'")
    # è¯»å–ä¸Šä¼ çš„å›¾ç‰‡æ–‡ä»¶ä¸ºå­—èŠ‚æµ
    image_bytes = await image.read()

    # è¿œç¨‹è°ƒç”¨æˆ‘ä»¬çš„æ ¸å¿ƒæ¨ç†å‡½æ•°
    output_image_bytes = Model().inference.remote(image_bytes, prompt)

    # å°†ç”Ÿæˆçš„å›¾ç‰‡ä»¥ PNG æ ¼å¼è¿”å›
    return Response(content=output_image_bytes, media_type="image/png")


@app.local_entrypoint()
def main(
    image_path: str = str(Path(__file__).parent.parent / "demo_images/dog.png"),
    output_path: str = "/tmp/qwen-image-edit/output.png",
    prompt: str = "æŠŠå®ƒå˜æˆä¸€åªç†ŠçŒ«",
):
    """
    æœ¬åœ°å…¥å£å‡½æ•°ï¼šè¯»å–æœ¬åœ°å›¾ç‰‡ï¼Œè°ƒç”¨äº‘ç«¯æ¨¡å‹ï¼Œä¿å­˜ç»“æœã€‚
    """
    input_image_path = Path(image_path)
    output_image_path = Path(output_path)
    
    if not input_image_path.exists():
        print(f"é”™è¯¯ï¼šæ‰¾ä¸åˆ°è¾“å…¥å›¾ç‰‡ {input_image_path}ã€‚")
        print("è¯·ç¡®ä¿åœ¨å½“å‰ç›®å½•ä¸‹æœ‰ä¸€å¼ åä¸º 'dog.png' çš„å›¾ç‰‡ï¼Œæˆ–è€…é€šè¿‡ --image-path æŒ‡å®šè·¯å¾„ã€‚")
        return

    print(f"ğŸ¨ æ­£åœ¨è¯»å–è¾“å…¥å›¾ç‰‡: {input_image_path}")
    input_image_bytes = input_image_path.read_bytes()

    print(f"ğŸ¨ æ­£åœ¨ä½¿ç”¨æŒ‡ä»¤ '{prompt}' ç¼–è¾‘å›¾ç‰‡...")
    output_image_bytes = Model().inference.remote(image_bytes, prompt)

    output_image_path.parent.mkdir(exist_ok=True, parents=True)
    print(f"ğŸ¨ æ­£åœ¨ä¿å­˜è¾“å‡ºå›¾ç‰‡åˆ°: {output_image_path}")
    output_image_path.write_bytes(output_image_bytes)