# ---
# output-directory: "/tmp/qwen-image-edit"
# ---

# # ä½¿ç”¨ Modal éƒ¨ç½²åƒé—®å›¾ç‰‡ç¼–è¾‘æ¨¡å‹ (Qwen-Image-Edit) - Diffusers æœ€ç»ˆç‰ˆ

# åœ¨è¿™ä¸ªä¾‹å­ä¸­ï¼Œæˆ‘ä»¬å°†åœ¨äº‘ç«¯GPUä¸Šè¿è¡Œé˜¿é‡Œçš„ Qwen-Image-Edit æ¨¡å‹ã€‚
# æˆ‘ä»¬å°†ä½¿ç”¨ Hugging Face å®˜æ–¹æ¨èçš„ diffusers åº“ä¸­çš„ QwenImageEditPipelineï¼Œ
# è¿™ç§æ–¹æ³•æ›´ç¨³å®šã€ä»£ç ä¹Ÿæ›´ç®€æ´ã€‚

# æ¨¡å‹ä¸»é¡µ: https://huggingface.co/Qwen/Qwen-Image-Edit

from io import BytesIO
from pathlib import Path

import modal

# 1. å®šä¹‰å®¹å™¨é•œåƒï¼šå®‰è£…æ‰€æœ‰å¿…è¦çš„åº“
image = (
    modal.Image.from_registry(
        "nvidia/cuda:12.1.1-devel-ubuntu22.04", # ä½¿ç”¨ä¸€ä¸ªå…¼å®¹çš„CUDAç‰ˆæœ¬
        add_python="3.11",
    )
    .apt_install("git")
    .pip_install(
        # **æœ€ç»ˆä¿®å¤**: ä¿®æ­£ PyTorch Nightly çš„åŒ…åä¸ºå®˜æ–¹åç§° 'torch' å’Œ 'torchvision'
        "torch",
        "torchvision",
        "transformers>=4.52.0",
        "diffusers>=0.27.0",
        "Pillow>=10.2.0",
        "huggingface-hub>=0.22.0",
        "accelerate>=0.29.0",
        # PyTorch çš„ Nightly index URL ä¸åŒï¼Œéœ€è¦æŒ‡å®š
        extra_index_url="https://download.pytorch.org/whl/nightly/cu121",
    )
)

# å®šä¹‰æ¨¡å‹åç§°å’Œç¼“å­˜è·¯å¾„
MODEL_NAME = "Qwen/Qwen-Image-Edit"
CACHE_DIR = Path("/cache")

# åˆ›å»ºä¸€ä¸ªæŒä¹…åŒ–çš„å­˜å‚¨å·æ¥ç¼“å­˜æ¨¡å‹ï¼Œé¿å…æ¯æ¬¡å¯åŠ¨éƒ½é‡æ–°ä¸‹è½½
cache_volume = modal.Volume.from_name("hf-hub-cache-qwen", create_if_missing=True)
volumes = {CACHE_DIR: cache_volume}

# ä»Modalå¹³å°å®‰å…¨åœ°è·å–HuggingFaceçš„APIå¯†é’¥
secrets = [modal.Secret.from_name("huggingface-secret")]

# é‡æ–°å‘½åAppä»¥ç¤ºåŒºåˆ†
app = modal.App("example-qwen-image-edit-diffusers")

@app.cls(
    image=image,
    gpu="H100",
    volumes=volumes,
    secrets=secrets,
    scaledown_window=240,
)
class Model:
    @modal.enter()
    def enter(self):
        """
        å®¹å™¨å¯åŠ¨æ—¶è¿è¡Œä¸€æ¬¡ï¼šä¸‹è½½å¹¶åŠ è½½æ¨¡å‹åˆ°GPUã€‚
        """
        import torch
        from diffusers import QwenImageEditPipeline

        print(f"æ­£åœ¨åŠ è½½æ¨¡å‹: {MODEL_NAME}")
        self.device = "cuda"

        self.pipe = QwenImageEditPipeline.from_pretrained(
            MODEL_NAME,
            torch_dtype=torch.bfloat16,
            cache_dir=CACHE_DIR,
        ).to(self.device)
        
        print("æ¨¡å‹åŠ è½½å®Œæˆï¼")

    @modal.method()
    def inference(self, image_bytes: bytes, prompt: str) -> bytes:
        """
        è¿™æ˜¯æ ¸å¿ƒçš„æ¨ç†å‡½æ•°ï¼Œä»æœ¬åœ°æ¥æ”¶å›¾ç‰‡å’ŒæŒ‡ä»¤ï¼Œåœ¨äº‘ç«¯GPUä¸Šæ‰§è¡Œï¼Œå¹¶è¿”å›æ–°å›¾ç‰‡ã€‚
        """
        import torch
        from PIL import Image

        print(f"æ”¶åˆ°æ–°çš„æ¨ç†ä»»åŠ¡ï¼ŒæŒ‡ä»¤: '{prompt}'")
        init_image = Image.open(BytesIO(image_bytes)).convert("RGB")

        edited_image = self.pipe(
            image=init_image,
            prompt=prompt,
            num_inference_steps=20,
            generator=torch.Generator(device=self.device).manual_seed(42),
        ).images[0]
        
        print("æ¨ç†å®Œæˆï¼Œæ­£åœ¨è¿”å›å›¾ç‰‡ã€‚")

        byte_stream = BytesIO()
        edited_image.save(byte_stream, format="PNG")
        output_image_bytes = byte_stream.getvalue()

        return output_image_bytes


@app.local_entrypoint()
def main(
    image_path: str = str(Path(__file__).parent.parent / "demo_images/dog.png"),
    output_path: str = "/tmp/qwen-image-edit/output.png",
    prompt: str = "æŠŠå®ƒå˜æˆä¸€åªç†ŠçŒ«",
):
    """
    æœ¬åœ°å…¥å£å‡½æ•°ï¼šè¯»å–æœ¬åœ°å›¾ç‰‡ï¼Œè°ƒç”¨äº‘ç«¯æ¨¡å‹ï¼Œä¿å­˜ç»“æœã€‚
    """
    input_image_path = Path(image_path)
    output_image_path = Path(output_path)
    
    if not input_image_path.exists():
        print(f"é”™è¯¯ï¼šæ‰¾ä¸åˆ°è¾“å…¥å›¾ç‰‡ {input_image_path}ã€‚")
        print("è¯·ç¡®ä¿åœ¨å½“å‰ç›®å½•ä¸‹æœ‰ä¸€å¼ åä¸º 'dog.png' çš„å›¾ç‰‡ï¼Œæˆ–è€…é€šè¿‡ --image-path æŒ‡å®šè·¯å¾„ã€‚")
        return

    print(f"ğŸ¨ æ­£åœ¨è¯»å–è¾“å…¥å›¾ç‰‡: {input_image_path}")
    input_image_bytes = input_image_path.read_bytes()

    print(f"ğŸ¨ æ­£åœ¨ä½¿ç”¨æŒ‡ä»¤ '{prompt}' ç¼–è¾‘å›¾ç‰‡...")
    output_image_bytes = Model().inference.remote(input_image_bytes, prompt)

    output_image_path.parent.mkdir(exist_ok=True, parents=True)
    print(f"ğŸ¨ æ­£åœ¨ä¿å­˜è¾“å‡ºå›¾ç‰‡åˆ°: {output_image_path}")
    output_image_path.write_bytes(output_image_bytes)

